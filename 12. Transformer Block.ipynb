{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e6d67fa",
   "metadata": {},
   "source": [
    "# Transformer Block Step-by-Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de9b6ac",
   "metadata": {},
   "source": [
    "## Step 1: Create sample input\n",
    "We start with sample data: 2 batches, 4 tokens each, 768 features per token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b0cbd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5637, 0.7317, 0.2979,  ..., 0.9264, 0.6331, 0.0364],\n",
       "         [0.2485, 0.4129, 0.7354,  ..., 0.9722, 0.5003, 0.8380],\n",
       "         [0.8403, 0.4896, 0.1170,  ..., 0.9261, 0.1429, 0.1976],\n",
       "         [0.9860, 0.9788, 0.5536,  ..., 0.1073, 0.2958, 0.1289]],\n",
       "\n",
       "        [[0.9273, 0.8357, 0.5234,  ..., 0.7678, 0.2702, 0.0584],\n",
       "         [0.8778, 0.1685, 0.2793,  ..., 0.1926, 0.9734, 0.2717],\n",
       "         [0.8775, 0.9506, 0.1665,  ..., 0.9037, 0.2363, 0.1772],\n",
       "         [0.0138, 0.7561, 0.4369,  ..., 0.4632, 0.5638, 0.0966]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "x = torch.rand(2, 4, 768)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542fe0d2",
   "metadata": {},
   "source": [
    "## Step 2: Save original input\n",
    "Keep a copy of the input for the first shortcut connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2db55b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5637, 0.7317, 0.2979,  ..., 0.9264, 0.6331, 0.0364],\n",
       "         [0.2485, 0.4129, 0.7354,  ..., 0.9722, 0.5003, 0.8380],\n",
       "         [0.8403, 0.4896, 0.1170,  ..., 0.9261, 0.1429, 0.1976],\n",
       "         [0.9860, 0.9788, 0.5536,  ..., 0.1073, 0.2958, 0.1289]],\n",
       "\n",
       "        [[0.9273, 0.8357, 0.5234,  ..., 0.7678, 0.2702, 0.0584],\n",
       "         [0.8778, 0.1685, 0.2793,  ..., 0.1926, 0.9734, 0.2717],\n",
       "         [0.8775, 0.9506, 0.1665,  ..., 0.9037, 0.2363, 0.1772],\n",
       "         [0.0138, 0.7561, 0.4369,  ..., 0.4632, 0.5638, 0.0966]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original1 = x.clone()\n",
    "original1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b5f5af",
   "metadata": {},
   "source": [
    "## Step 3: Normalize before Attention\n",
    "Apply LayerNorm to standardize token representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a205fd82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1819,  0.7645, -0.7394,  ...,  1.4394,  0.4227, -1.6458],\n",
       "         [-0.8196, -0.2754,  0.7923,  ...,  1.5764,  0.0141,  1.1320],\n",
       "         [ 1.1721, -0.0435, -1.3351,  ...,  1.4694, -1.2455, -1.0558],\n",
       "         [ 1.5732,  1.5483,  0.0924,  ..., -1.4356, -0.7903, -1.3617]],\n",
       "\n",
       "        [[ 1.5325,  1.2145,  0.1308,  ...,  0.9788, -0.7476, -1.4826],\n",
       "         [ 1.3192, -1.1343, -0.7510,  ..., -1.0511,  1.6497, -0.7774],\n",
       "         [ 1.3232,  1.5765, -1.1419,  ...,  1.4141, -0.9000, -1.1049],\n",
       "         [-1.6858,  0.8792, -0.2239,  ..., -0.1329,  0.2149, -1.3996]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm1 = nn.LayerNorm(768)\n",
    "x = norm1(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe07276",
   "metadata": {},
   "source": [
    "## Step 4: Simulate Attention\n",
    "Use a Linear layer to simulate attention output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cb8c993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9538,  0.7173, -0.1554,  ...,  0.2091,  0.7591, -0.3793],\n",
       "         [-0.0387, -0.2015,  0.0606,  ..., -0.8319,  0.7434,  0.3535],\n",
       "         [-0.3209, -0.0594, -0.1047,  ...,  0.8083, -0.2487,  0.7872],\n",
       "         [ 1.0478, -0.3104,  0.1779,  ...,  0.0592, -0.8362,  0.2143]],\n",
       "\n",
       "        [[ 0.4057,  0.3540,  0.4033,  ..., -0.2086, -1.5634,  0.5781],\n",
       "         [-0.0765, -0.1450,  0.1571,  ..., -0.4221,  0.4306,  0.0784],\n",
       "         [ 0.6721, -0.6297, -0.0070,  ...,  0.6114,  0.2340, -0.1225],\n",
       "         [ 0.5869, -0.2598,  0.6906,  ..., -0.1456, -0.2834,  0.2620]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_layer = nn.Linear(768, 768)\n",
    "x = attention_layer(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd3b1ea",
   "metadata": {},
   "source": [
    "## Step 5: Dropout after Attention\n",
    "Apply dropout to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b373d61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0598,  0.7970, -0.1726,  ...,  0.2324,  0.8434, -0.4214],\n",
       "         [-0.0430, -0.2239,  0.0674,  ..., -0.9243,  0.8260,  0.3927],\n",
       "         [-0.3566, -0.0660, -0.1163,  ...,  0.8981, -0.2763,  0.8747],\n",
       "         [ 1.1643, -0.3449,  0.1976,  ...,  0.0658, -0.9291,  0.2381]],\n",
       "\n",
       "        [[ 0.0000,  0.3934,  0.4481,  ..., -0.2317, -1.7372,  0.6423],\n",
       "         [-0.0850, -0.1611,  0.1746,  ..., -0.0000,  0.4785,  0.0871],\n",
       "         [ 0.0000, -0.6997, -0.0078,  ...,  0.6793,  0.2600, -0.1361],\n",
       "         [ 0.6521, -0.2887,  0.7674,  ..., -0.1617, -0.3148,  0.2912]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout = nn.Dropout(0.1)\n",
    "x = dropout(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bf0ffd",
   "metadata": {},
   "source": [
    "## Step 6: Add first Shortcut Connection\n",
    "Add the original input back to preserve memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "278c82af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-4.9615e-01,  1.5287e+00,  1.2527e-01,  ...,  1.1588e+00,\n",
       "           1.4766e+00, -3.8505e-01],\n",
       "         [ 2.0548e-01,  1.8895e-01,  8.0274e-01,  ...,  4.7926e-02,\n",
       "           1.3263e+00,  1.2307e+00],\n",
       "         [ 4.8374e-01,  4.2369e-01,  7.0616e-04,  ...,  1.8241e+00,\n",
       "          -1.3348e-01,  1.0723e+00],\n",
       "         [ 2.1503e+00,  6.3385e-01,  7.5121e-01,  ...,  1.7313e-01,\n",
       "          -6.3337e-01,  3.6700e-01]],\n",
       "\n",
       "        [[ 9.2735e-01,  1.2291e+00,  9.7149e-01,  ...,  5.3602e-01,\n",
       "          -1.4669e+00,  7.0069e-01],\n",
       "         [ 7.9277e-01,  7.4269e-03,  4.5393e-01,  ...,  1.9259e-01,\n",
       "           1.4519e+00,  3.5886e-01],\n",
       "         [ 8.7752e-01,  2.5090e-01,  1.5870e-01,  ...,  1.5830e+00,\n",
       "           4.9623e-01,  4.1105e-02],\n",
       "         [ 6.6588e-01,  4.6739e-01,  1.2042e+00,  ...,  3.0146e-01,\n",
       "           2.4900e-01,  3.8777e-01]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x + original1\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887c7905",
   "metadata": {},
   "source": [
    "## Step 7: Save for second Shortcut\n",
    "Save a copy before feed-forward processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc53aad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-4.9615e-01,  1.5287e+00,  1.2527e-01,  ...,  1.1588e+00,\n",
       "           1.4766e+00, -3.8505e-01],\n",
       "         [ 2.0548e-01,  1.8895e-01,  8.0274e-01,  ...,  4.7926e-02,\n",
       "           1.3263e+00,  1.2307e+00],\n",
       "         [ 4.8374e-01,  4.2369e-01,  7.0616e-04,  ...,  1.8241e+00,\n",
       "          -1.3348e-01,  1.0723e+00],\n",
       "         [ 2.1503e+00,  6.3385e-01,  7.5121e-01,  ...,  1.7313e-01,\n",
       "          -6.3337e-01,  3.6700e-01]],\n",
       "\n",
       "        [[ 9.2735e-01,  1.2291e+00,  9.7149e-01,  ...,  5.3602e-01,\n",
       "          -1.4669e+00,  7.0069e-01],\n",
       "         [ 7.9277e-01,  7.4269e-03,  4.5393e-01,  ...,  1.9259e-01,\n",
       "           1.4519e+00,  3.5886e-01],\n",
       "         [ 8.7752e-01,  2.5090e-01,  1.5870e-01,  ...,  1.5830e+00,\n",
       "           4.9623e-01,  4.1105e-02],\n",
       "         [ 6.6588e-01,  4.6739e-01,  1.2042e+00,  ...,  3.0146e-01,\n",
       "           2.4900e-01,  3.8777e-01]]], grad_fn=<CloneBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original2 = x.clone()\n",
    "original2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4e87fa",
   "metadata": {},
   "source": [
    "## Step 8: Normalize before Feed Forward\n",
    "Apply LayerNorm again for stabilization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1d6c40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4982,  1.4916, -0.5807,  ...,  0.9454,  1.4146, -1.3342],\n",
       "         [-0.3874, -0.4113,  0.4741,  ..., -0.6147,  1.2293,  1.0914],\n",
       "         [-0.0512, -0.1375, -0.7458,  ...,  1.8763, -0.9387,  0.7951],\n",
       "         [ 2.5579,  0.1697,  0.3545,  ..., -0.5559, -1.8260, -0.2506]],\n",
       "\n",
       "        [[ 0.7066,  1.1506,  0.7715,  ...,  0.1307, -2.8166,  0.3731],\n",
       "         [ 0.4155, -0.7356, -0.0811,  ..., -0.4642,  1.3816, -0.2205],\n",
       "         [ 0.5697, -0.3472, -0.4821,  ...,  1.6021,  0.0118, -0.6542],\n",
       "         [ 0.2159, -0.0654,  0.9791,  ..., -0.3007, -0.3750, -0.1783]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm2 = nn.LayerNorm(768)\n",
    "x = norm2(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcb755d",
   "metadata": {},
   "source": [
    "## Step 9: Feed Forward (Linear → GELU → Linear)\n",
    "Transform token representations individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3082acaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1939, -0.1433, -0.1853,  ..., -0.2267, -0.1775,  0.0464],\n",
       "         [ 0.0832, -0.1158,  0.0877,  ..., -0.0754, -0.1419, -0.1205],\n",
       "         [-0.0489, -0.0471, -0.2389,  ...,  0.0364, -0.3158, -0.0355],\n",
       "         [-0.1471,  0.2842,  0.0381,  ..., -0.1861,  0.0634,  0.3066]],\n",
       "\n",
       "        [[ 0.2106,  0.2389,  0.0767,  ..., -0.0223,  0.1004, -0.2162],\n",
       "         [-0.1819,  0.2184,  0.0079,  ..., -0.0982, -0.1507, -0.0384],\n",
       "         [-0.0434, -0.3403, -0.0538,  ..., -0.0171,  0.1861,  0.1985],\n",
       "         [-0.7467, -0.1399,  0.0155,  ...,  0.1601, -0.1039,  0.0095]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff1 = nn.Linear(768, 768)\n",
    "gelu = nn.GELU()\n",
    "ff2 = nn.Linear(768, 768)\n",
    "x = ff1(x)\n",
    "x = gelu(x)\n",
    "x = ff2(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e36f71",
   "metadata": {},
   "source": [
    "## Step 10: Dropout after Feed Forward\n",
    "Apply dropout to maintain generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65463351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2155, -0.1592, -0.2059,  ..., -0.2519, -0.1972,  0.0515],\n",
       "         [ 0.0925, -0.1287,  0.0974,  ..., -0.0838, -0.1576, -0.1339],\n",
       "         [-0.0543, -0.0523, -0.0000,  ...,  0.0405, -0.3509, -0.0394],\n",
       "         [-0.1634,  0.3157,  0.0423,  ..., -0.2068,  0.0704,  0.0000]],\n",
       "\n",
       "        [[ 0.2340,  0.2654,  0.0852,  ..., -0.0248,  0.1116, -0.2402],\n",
       "         [-0.2021,  0.2427,  0.0087,  ..., -0.1091, -0.1674, -0.0426],\n",
       "         [-0.0482, -0.3781, -0.0597,  ..., -0.0189,  0.2067,  0.2205],\n",
       "         [-0.8296, -0.1554,  0.0172,  ...,  0.1778, -0.1154,  0.0000]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = dropout(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb939891",
   "metadata": {},
   "source": [
    "## Step 11: Add second Shortcut Connection\n",
    "Add original input again to preserve structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16e68cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-7.1164e-01,  1.3695e+00, -8.0656e-02,  ...,  9.0690e-01,\n",
       "           1.2794e+00, -3.3353e-01],\n",
       "         [ 2.9795e-01,  6.0304e-02,  9.0013e-01,  ..., -3.5875e-02,\n",
       "           1.1687e+00,  1.0968e+00],\n",
       "         [ 4.2942e-01,  3.7140e-01,  7.0616e-04,  ...,  1.8646e+00,\n",
       "          -4.8436e-01,  1.0328e+00],\n",
       "         [ 1.9869e+00,  9.4959e-01,  7.9354e-01,  ..., -3.3699e-02,\n",
       "          -5.6294e-01,  3.6700e-01]],\n",
       "\n",
       "        [[ 1.1614e+00,  1.4945e+00,  1.0567e+00,  ...,  5.1121e-01,\n",
       "          -1.3553e+00,  4.6046e-01],\n",
       "         [ 5.9071e-01,  2.5008e-01,  4.6265e-01,  ...,  8.3491e-02,\n",
       "           1.2844e+00,  3.1624e-01],\n",
       "         [ 8.2929e-01, -1.2719e-01,  9.8965e-02,  ...,  1.5641e+00,\n",
       "           7.0296e-01,  2.6165e-01],\n",
       "         [-1.6374e-01,  3.1199e-01,  1.2214e+00,  ...,  4.7929e-01,\n",
       "           1.3360e-01,  3.8777e-01]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x + original2\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790f8107",
   "metadata": {},
   "source": [
    "## Final Output Shape\n",
    "The shape should remain consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d3b0aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "print('Final shape:', x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4117f373-67fb-4750-b4ae-ac598f50397d",
   "metadata": {},
   "source": [
    "### Each step helps the model:\n",
    "- Remember context\n",
    "- Understand relationships\n",
    "- And transform language into magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c361fc-b3eb-4be9-86c2-8c61d957632d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
